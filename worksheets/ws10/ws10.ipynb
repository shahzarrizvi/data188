{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "from prob140 import *\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 10 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. One-Way ANOVA\n",
    "The data consist of a random sample of 400 home sales in a part of Ohio over the period 2006 to 2010. For your convenience, we have placed the data in a `Table` called `sales` as well as in a `pandas` dataframe called `df_sales`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('sales.csv')\n",
    "sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row represents a sale. The columns:\n",
    "\n",
    "- `Build Period`: The period in which the house was built. `'2000+'` means \"Year 2000 or later\".\n",
    "- `Lot Area`: Area of the lot in square feet\n",
    "- `House Area`: Total area of the house in square feet, including garages, decks, etc.\n",
    "- `Year Sold`: Self-explanatory\n",
    "- `Sale Price`: In dollars as at the time of sale; not adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** We will compare the distributions of lot areas for the different build periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(i)** Draw a [boxplot](https://seaborn.pydata.org/generated/seaborn.boxplot.html) of the all distributions. Since the build periods have a chronological order, we recommend using the option `order=chron_order` with `sns.boxplot`, for the list `chron_order` created in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chron_order = ['Pre 1940', '1940-1959', '1960-1979', '1980-1999', '2000+']\n",
    "lots = sales[['Build Period', 'Lot Area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (a)(i)\n",
    "\n",
    "sns.boxplot(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(ii)** Find the observed group means. You are welcome to display the group means in any format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (a)(ii)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(iii)** With the groups as the build periods, state the one-way ANOVA model for lot areas. In what ways is the boxplot consistent or inconsistent with the model? Discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  No model is perfect. We are going to start by using the one-way ANOVA model above, in spite of its imperfections. \n",
    "\n",
    "**(i)** State the null hypothesis that all the group means are equal, in terms of the one-way ANOVA model you stated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(ii)** To test this null hypothesis, start by creating the samples of lot sizes in each group. You are welcome to store the group samples in any form as long as you can access each sample easily. Use as many lines and cells as you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (b)(ii)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(iii)** Now use `stats.f_oneway` to conduct the $F$-test of the null hypothesis. It takes the group samples as arguments, each as a separate array or list, as in `stats.f_oneway(gr1_sample, gr2_sample, gr3_sample)` when there are 3 groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (b)(iii)\n",
    "\n",
    "stats.f_oneway(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(iv)** What is the conclusion of the test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Use the steps below to calculate the $F$-statistic without using `SciPy` and check that you get the same result as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 400\n",
    "y = lots['Lot Area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(i)** Refer to the notation used in seminar. Recall that the total sum of squares is defined as \n",
    "\n",
    "$${\\rm SST} = \\sum_{g=1}^G \\sum_{i=1}^{n_g} (Y_{gi} - \\bar{Y}_{\\cdot\\cdot})^2$$\n",
    "\n",
    "and that the \"within groups\" sum of squares is defined by \n",
    "\n",
    "$${\\rm SSW} = \\sum_{g=1}^G \\sum_{i=1}^{n_g} (Y_{gi} - \\bar{Y}_{g\\cdot})^2$$\n",
    "\n",
    "Keep in mind that if an array `x` contains the values $x_1, x_2, \\ldots, x_m$, then `np.var(x)` evaluates to the variance $\\frac{1}{m}\\sum_{k=1}^m (x_k - \\bar{x})^2$. Use this along with appropriate array operations to find the observed values of $\\rm SST$ and $\\rm SSW$, and hence also $\\rm SSB$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (c)(i)\n",
    "# Use as many lines as you need.\n",
    "\n",
    "...\n",
    "\n",
    "sst = ...\n",
    "ssw = ...\n",
    "ssb = ...\n",
    "sst, ssw, ssb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(ii)** Now find the observed value of the $F$-statistic and check that it agrees with the statistic provided by `stats.f_oneway`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (c)(ii)\n",
    "\n",
    "f_stat = ...\n",
    "f_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** Let's find the $p$ value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pdf of the $F$ distribution with `df1` and `df2` degrees of freedom evaluated at the point `x` can be found by `stats.f.pdf(x, df1, df2)`. Use this to plot the distribution of the $F$ statistic under the null hypothesis. Based on your plot, should your $p$ value be large or small?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (d)(i)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(ii)** The cdf of the $F$ distribution with `df1` and `df2` degrees of freedom evaluated at the point `x` can be found by `stats.f.cdf(x, df1, df2)`. Use this to write an expression that evaluates to the $p$ value of the $F$-test above, and confirm that it agrees with the $p$ value provided by `stats.f_oneway`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (d)(ii)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)** Let's consider a nonparametric approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(i)** Refer again to the boxplot and provide one major advantage of rank-based methods over normality assumptions for the data we are analyzing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(ii)** Now assume that for each $g$, the lot areas in Group $g$ are i.i.d. according to some distribution $F_g$. State the null hypothesis in terms of these distributions instead of in terms of the underlying means as you did earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(iii)** To perform the Kruskal-Wallis test of your null hypothesis, simply replace `stats.f_oneway` by `stats.kruskal`. The arguments are exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (e)(iii)\n",
    "\n",
    "... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(iv)** Which hypothesis is better supported by the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data have ties, so we won't go into calculating the test statistic directly from the ranks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
